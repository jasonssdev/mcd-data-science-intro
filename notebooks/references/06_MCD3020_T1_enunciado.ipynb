{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fl7zUUWBV6mS"
   },
   "outputs": [],
   "source": [
    "#código de inicio\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QyhlZPUEwufO"
   },
   "source": [
    "# <img style=\"float: left; padding-right: 20px; width: 100px\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/84/Escudo_de_la_Pontificia_Universidad_Cat%C3%B3lica_de_Chile.svg/1920px-Escudo_de_la_Pontificia_Universidad_Cat%C3%B3lica_de_Chile.svg.png\"> MCD3020 - Introducción a Ciencia de Datos\n",
    "**Pontificia Universidad Católica de Chile**<br>\n",
    "**Magíster en Ciencia de Datos**<br>\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFn7QeLu3xOO"
   },
   "source": [
    "# Tarea 1: Extracción de datos mediante webscraping.\n",
    "\n",
    "***\n",
    "## Instrucciones Generales:\n",
    "- Esta Tarea debe ser desarrollada completamente en lenguaje de programación Python, en este mismo Notebook.\n",
    "- El Notebook debe estar  ordenado, seguir buenas prácticas de escritura y programación, e incluir comentarios o celdas de markdown suficientes para explicar claramente todos lo códigos computacionales.\n",
    "- El Notebook ya contiene algunas celdas marcadas con el comentario `#código de inicio`. Estas celdas han sido incluidas como ayuda para el desarrollo de la Tarea, y pueden ser ejecutadas tal como están.\n",
    "- Las celdas marcadas como `#completar código` tienen un código parcial que debe ser completado para poder ser ejecutado. Ud debe agregar todas las líneas o bloques de código necesarios para desarrollar correctamente cada punto de la tarea. También puede eliminar estas celdas y partir el código desde cero si le resulta más conveniente.\n",
    "- Para el desarrollo de cada pregunta, se sugiere agregar las celdas de código y/o markdown necesarias bajo el enunciado de la misma.\n",
    "- Asegúrese de guardar los cambios en su Notebook antes de entregarlo.\n",
    "\n",
    "***\n",
    "## Introducción.\n",
    "\n",
    "El trabajo de científico de datos fue catalogado hace algunos años por Harvard Bussiness Review como \"el trabajo más atractivo del siglo XXI\" [(Davenport & Patil 2012)](https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century). Desde entonces, se ha comprobado un aumento constante de la demanda por profesionales expertos datos, y se espera que tanto la creación de puestos trabajos como los salarios sigan al alza en los próximos años. Los siguienes artículos de prensa y difusión ilustran esta situación:\n",
    "\n",
    "https://www.smithhanley.com/2022/01/04/data-science-in-2022/\n",
    "https://www.bbva.com/es/big-data-la-demanda-de-talento-experto-sigue-creciendo/\n",
    "\n",
    "Los estudios citados hacen referencia a mercados laborales en Europa y Estados Unidos. Suponga que ud. está a cargo del desarrollo de un estudio del mercado laboral de científicos de datos en latinoamérica, para lo cual necesita construir una base de datos con las ofertas de trabajo publicadas en distintos países de la región.\n",
    "\n",
    "El objetivo de esta tarea es usar técnicas de webscrapping para extraer datos de ofertas para científicos de datos publicadas en un portal abierto de empleos (www.linkedin.com/jobs). \n",
    "\n",
    "\n",
    "**Nota 1**: Este trabajo fue inspirado de [Tutorial](https://www.youtube.com/watch?v=eN_3d4JrL_w&ab_channel=IzzyAnalytics)\n",
    "\n",
    "**Nota 2**: Puede revisar los términos de crawling de Linkedin en https://www.linkedin.com/legal/crawling-terms.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_ICRQTPxUYI"
   },
   "source": [
    "#### 1. Ingrese a la página web de www.linkedin.com/jobs/search (no es necesario acceder con una cuenta de LinkedIn). Haga click en el botón `Buscar Empleos` y realice una búsqueda de empleos para *data scientist* (o *científico/a de datos*) en la capital de su país (u otra ciudad de su interés). \n",
    "\n",
    "- Inspeccione y analice el código fuente de la página de resultados, para entender la estructura de su código HTML.\n",
    "\n",
    "- En base a su inspección del código HTML, responda: ¿Qué elemento del código le permite llegar exactamente a la lista de anuncios de empleo? [1 punto]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9PBdfKE4xUYJ"
   },
   "source": [
    "#### 2. Extraiga la lista de anuncios de trabajo arrojados por su búsqueda en LinkedIn.  [1 punto]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "knsl-A5cxUYK"
   },
   "outputs": [],
   "source": [
    "#complete este código\n",
    "position = 'data%20scientist'\n",
    "location = ###completar\n",
    "url_search = 'https://www.linkedin.com/jobs/search/?keywords=%s&location=%s'%(position, location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6jJqLmYP3Ux5"
   },
   "outputs": [],
   "source": [
    "#código de inicio\n",
    "\n",
    "#Para evitar que la página web piense que usted es un bot, al realizar el request utilice algunos de los siguientes encabezados: \n",
    "head = {'User-Agent': 'Mozilla/5.0'}\n",
    "#head = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.84 Safari/537.36'}\n",
    "#head = {'user-agent':'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Mobile Safari/537.36'}\n",
    "#head = {'user-agent':'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Mobile Safari/537.36'}\n",
    "#head = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.84 Safari/537.36',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BqChn4MZxUYL"
   },
   "outputs": [],
   "source": [
    "#complete este código\n",
    "\n",
    "response = requests.get(url_search,###)\n",
    "soup = ###\n",
    "joblist = soup.find(###)\n",
    "alljobs=joblist.find_all(###,class_=\"###\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W5AERO-kxUYM"
   },
   "source": [
    "#### 3. Seleccione por ahora sólo el primer anuncio de la lista, y extraiga la información de:  título del trabajo, nombre de la compañía, localización, y URL del anuncio  [2 puntos].\n",
    "\n",
    "Nota: Por localización se entiende la ciudad, comuna o municipio indicado en el anuncio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pOcOSwFuxUYN"
   },
   "outputs": [],
   "source": [
    "#complete este código\n",
    "\n",
    "###### Pueden incluir una función para que en el texto se eliminen los saltos de lineas, espacios en blanco, etc.\n",
    "\n",
    "job=alljobs[0]\n",
    "\n",
    "location=job.###\n",
    "title=job.###\n",
    "company=job.###\n",
    "joburl=job.###    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uf1pPnWTxUYO"
   },
   "source": [
    "#### 4. En base a los puntos anteriores, programe una rutina para extraer la información de localización,  título del trabajo, nombre de la compañía, localización, y URL del anuncio para *todos* los trabajos arrojados por su búsqueda de Linkedin, y almacenar los datos en un dataframe de pandas  [3 puntos]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yajotXq1xUYO"
   },
   "outputs": [],
   "source": [
    "#complete este código\n",
    "df_jobs= pd.DataFrame(columns = ['Location', 'Title', 'Company', 'Url'])\n",
    "\n",
    "##### Tienen su dataframe vacío, pueden iterar en todos los trabajos descargos e ir extranyendo la información. Exactamente como lo hicieron con un solo trabajo.\n",
    "\n",
    "# Aqui tienen distintas formas de ir incluyendo la información al dataframe, pueden hacer append, loc, hacer una lista o diccionario con la información y luego \n",
    "### Transformarlo en dataframe\n",
    "\n",
    "##### Método de indexación: .iloc usa indexación basada en números enteros, mientras que .loc usa indexación basada en etiquetas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5AzJvKlxxUYP"
   },
   "source": [
    "#### 5. Exporte su dataframe a un archivo en formato .csv.  [1 punto]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dL4-uR9_QQOL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qi4sOfg6xUYP"
   },
   "source": [
    "#### 6. ¿Cuántas ofertas de empleo contiene su dataframe, y cuántos resultados hay en total en la búsqueda de Linkedin? Comente sobre las diferencias o coincidencias, y explique qué debería hacer para extraer todos los resultados disponibles en Linkedin (en palabras, no es necesario implementarlo)  [1 punto]\n",
    "\n",
    "Hint: Verifique el número de páginas de resultados, y la URL correspondiente a cada una de ellas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tg8fwWroxUYP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
